{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "RangeIndex: 672 entries, 0 to 671\n",
       "Data columns (total 13 columns):\n",
       " #   Column             Non-Null Count  Dtype  \n",
       "---  ------             --------------  -----  \n",
       " 0   Job Title          672 non-null    object \n",
       " 1   Salary Estimate    672 non-null    object \n",
       " 2   Job Description    672 non-null    object \n",
       " 3   Rating             672 non-null    float64\n",
       " 4   Company Name       672 non-null    object \n",
       " 5   Location           672 non-null    object \n",
       " 6   Headquarters       672 non-null    object \n",
       " 7   Size               672 non-null    object \n",
       " 8   Founded            672 non-null    int64  \n",
       " 9   Type of ownership  672 non-null    object \n",
       " 10  Industry           672 non-null    object \n",
       " 11  Sector             672 non-null    object \n",
       " 12  Revenue            672 non-null    object \n",
       "dtypes: float64(1), int64(1), object(11)\n",
       "memory usage: 68.4+ KB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "df_postings = pd.read_csv(\"C:/Users/marioreyes/Desktop/Data Analysis Practice/Python/Project/Job Postings/Uncleaned_DS_jobs.csv\")\n",
    "df_postings.drop(columns=['index','Competitors'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Job Title               Salary Estimate  \\\n",
       "0  Sr Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "1     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "2     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "3     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "4     Data Scientist  $137K-$171K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n",
       "1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n",
       "2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n",
       "3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "\n",
       "              Company Name       Location            Headquarters  \\\n",
       "0         Healthfirst\\n3.1   New York, NY            New York, NY   \n",
       "1             ManTech\\n4.2  Chantilly, VA             Herndon, VA   \n",
       "2      Analysis Group\\n3.8     Boston, MA              Boston, MA   \n",
       "3             INFICON\\n3.5     Newton, MA  Bad Ragaz, Switzerland   \n",
       "4  Affinity Solutions\\n2.9   New York, NY            New York, NY   \n",
       "\n",
       "                      Size  Founded        Type of ownership  \\\n",
       "0   1001 to 5000 employees     1993   Nonprofit Organization   \n",
       "1  5001 to 10000 employees     1968         Company - Public   \n",
       "2   1001 to 5000 employees     1981  Private Practice / Firm   \n",
       "3    501 to 1000 employees     2000         Company - Public   \n",
       "4      51 to 200 employees     1998        Company - Private   \n",
       "\n",
       "                                Industry             Sector  \\\n",
       "0                     Insurance Carriers          Insurance   \n",
       "1                 Research & Development  Business Services   \n",
       "2                             Consulting  Business Services   \n",
       "3  Electrical & Electronic Manufacturing      Manufacturing   \n",
       "4                Advertising & Marketing  Business Services   \n",
       "\n",
       "                      Revenue  \n",
       "0    Unknown / Non-Applicable  \n",
       "1      $1 to $2 billion (USD)  \n",
       "2  $100 to $500 million (USD)  \n",
       "3  $100 to $500 million (USD)  \n",
       "4    Unknown / Non-Applicable  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and Formatting\n",
    "#print(df_postings.groupby('Salary Estimate')['Salary Estimate'].count())\n",
    "\n",
    "#Splitting Salary Estimate Column\n",
    "#Splitting salary into two columns (since we know there is only one - in each entry)\n",
    "df_postings[['Lower Salary Estimate','new']]= df_postings['Salary Estimate'].str.split('-',expand=True)\n",
    "df_postings['Lower Salary Estimate'] = df_postings['Lower Salary Estimate'].str.strip('$K').astype('int')*1000\n",
    "\n",
    "#Splitting salary into two columns. Here we use n=1 since there are multiple \" \" in each entry\n",
    "df_postings[['High Salary Estimate','new_2']]= df_postings['new'].str.split('K',n=1,expand=True)\n",
    "df_postings['High Salary Estimate'] = df_postings['High Salary Estimate'].str.strip('$K ').astype('int')*1000\n",
    "#Dropping Columns that we generated and no longer need\n",
    "df_postings.drop(columns=['new','new_2'], inplace=True)\n",
    "\n",
    "\n",
    "#Cleaning Company Name\n",
    "df_postings[['Company Name2','new']]= df_postings['Company Name'].str.split('\\n',n=1,expand=True)\n",
    "df_postings.drop(columns=['new','Company Name'], inplace=True)\n",
    "\n",
    "df_postings.rename(columns={'Company Name2': 'Company Name'}, inplace=True)\n",
    "#There were some company names that did not have the decimal points. Checking one of those instances to make sure the strip worked correctly\n",
    "#print(df_postings['Company Name'].str.contains('Radical Convergence').any())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Size column\n",
    "\n",
    "df_postings[['Size2','new']]= df_postings['Size'].str.split(' ',n=1,expand=True)\n",
    "#Looks like there are some values with \"+\" so lets strip those\n",
    "df_postings['Size2'] = df_postings['Size2'].str.strip('+')\n",
    "#Looks like there are some values labeled as unknown. Let's change those to 1\n",
    "df_postings['Size2'] = df_postings['Size2'].replace('Unknown', '1')\n",
    "#There's also values that are -1. Looks like those values have a bunch of missing entries. Let's drop them\n",
    "df_postings = df_postings[df_postings['Size2'] != \"-1\"]\n",
    "\n",
    "df_postings['Size2'] = df_postings['Size2'].astype('int')\n",
    "df_postings.rename(columns={'Size2': 'Lower Staff Size'}, inplace=True)\n",
    "\n",
    "\n",
    "df_postings[['Size3','new2']]= df_postings['new'].str.split('to ',n=2,expand=True)\n",
    "df_postings[['Size4','new3']]= df_postings['new2'].str.split(' ',n=1,expand=True)\n",
    "#Seems like we can't convert column into int bc there are None Values. Let's check the breakdown of the column\n",
    "df_postings.rename(columns={'Size4': 'Higher Staff Size'}, inplace=True)\n",
    "df_postings.drop(columns=['new','new2','new3','Size3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "Index: 645 entries, 0 to 671\n",
       "Data columns (total 17 columns):\n",
       " #   Column                 Non-Null Count  Dtype  \n",
       "---  ------                 --------------  -----  \n",
       " 0   Job Title              645 non-null    object \n",
       " 1   Salary Estimate        645 non-null    object \n",
       " 2   Job Description        645 non-null    object \n",
       " 3   Rating                 645 non-null    float64\n",
       " 4   Location               645 non-null    object \n",
       " 5   Headquarters           645 non-null    object \n",
       " 6   Size                   645 non-null    object \n",
       " 7   Founded                645 non-null    int64  \n",
       " 8   Type of ownership      645 non-null    object \n",
       " 9   Industry               645 non-null    object \n",
       " 10  Sector                 645 non-null    object \n",
       " 11  Revenue                645 non-null    object \n",
       " 12  Lower Salary Estimate  645 non-null    int64  \n",
       " 13  High Salary Estimate   645 non-null    int64  \n",
       " 14  Company Name           645 non-null    object \n",
       " 15  Lower Staff Size       645 non-null    int64  \n",
       " 16  Higher Staff Size      548 non-null    object \n",
       "dtypes: float64(1), int64(4), object(12)\n",
       "memory usage: 90.7+ KB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_postings.info()\n",
    "#Looks like there are None values in the higher staff column. Let's see how those values look like compared to low staff colimn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Lower Staff Size Higher Staff Size\n",
       "6               10000              None\n",
       "31              10000              None\n",
       "41              10000              None\n",
       "45              10000              None\n",
       "51              10000              None\n",
       "..                ...               ...\n",
       "644             10000              None\n",
       "645             10000              None\n",
       "651             10000              None\n",
       "659             10000              None\n",
       "661             10000              None\n",
       "\n",
       "[97 rows x 2 columns]\n",
       "Higher Staff Size\n",
       "1000      77\n",
       "10000     61\n",
       "200      135\n",
       "50        86\n",
       "500       85\n",
       "5000     104\n",
       "NaN        0\n",
       "Name: Higher Staff Size, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_postings[df_postings['Higher Staff Size'].isnull()][['Lower Staff Size','Higher Staff Size']])\n",
    "print(df_postings.groupby('Higher Staff Size', dropna=False)['Higher Staff Size'].count())\n",
    "\n",
    "#The original dataset had entries that read \"10000+\". Since we dont have a max value, for this practice we will create a max value of 20000\n",
    "df_postings.loc[df_postings['Lower Staff Size'] == 10000, 'Higher Staff Size'] = df_postings.loc[df_postings['Lower Staff Size'] == 10000, 'Higher Staff Size'].fillna('20000')\n",
    "\n",
    "#Looks like there is another None value when the lower staff size is 1. If you remember we changed those with \"unknown\"\n",
    "#values to 1. We don't have a range of values for these companies, so we will set a max value of 50\n",
    "df_postings.loc[df_postings['Lower Staff Size'] == 1, 'Higher Staff Size'] = df_postings.loc[df_postings['Lower Staff Size'] == 1, 'Higher Staff Size'].fillna(50)\n",
    "\n",
    "#There are no more None values in the column. So now let's convert the column into an int\n",
    "df_postings['Higher Staff Size'] = df_postings['Higher Staff Size'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "Index: 645 entries, 0 to 671\n",
       "Data columns (total 17 columns):\n",
       " #   Column                 Non-Null Count  Dtype  \n",
       "---  ------                 --------------  -----  \n",
       " 0   Job Title              645 non-null    object \n",
       " 1   Salary Estimate        645 non-null    object \n",
       " 2   Job Description        645 non-null    object \n",
       " 3   Rating                 645 non-null    float64\n",
       " 4   Location               645 non-null    object \n",
       " 5   Headquarters           645 non-null    object \n",
       " 6   Size                   645 non-null    object \n",
       " 7   Founded                645 non-null    int64  \n",
       " 8   Type of ownership      645 non-null    object \n",
       " 9   Industry               645 non-null    object \n",
       " 10  Sector                 645 non-null    object \n",
       " 11  Revenue                645 non-null    object \n",
       " 12  Lower Salary Estimate  645 non-null    int64  \n",
       " 13  High Salary Estimate   645 non-null    int64  \n",
       " 14  Company Name           645 non-null    object \n",
       " 15  Lower Staff Size       645 non-null    int64  \n",
       " 16  Higher Staff Size      645 non-null    int64  \n",
       "dtypes: float64(1), int64(5), object(11)\n",
       "memory usage: 90.7+ KB\n",
       "None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_postings.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Unknown / Non-Applicable\n",
       "1          $1 to $2 billion (USD)\n",
       "2      $100 to $500 million (USD)\n",
       "3      $100 to $500 million (USD)\n",
       "4        Unknown / Non-Applicable\n",
       "                  ...            \n",
       "665     $50 to $100 million (USD)\n",
       "666    $100 to $500 million (USD)\n",
       "667      Unknown / Non-Applicable\n",
       "670        $1 to $5 million (USD)\n",
       "671        $1 to $2 billion (USD)\n",
       "Name: Revenue, Length: 645, dtype: object\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_postings['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postings[['Revenue2','new']]= df_postings['Revenue'].str.split(' ',n=1,expand=True)\n",
    "df_postings[['Revenue3','new2']]= df_postings['new'].str.split('$',expand=True)\n",
    "df_postings[['Revenue4','new3']]= df_postings['new2'].str.split(' ',n=1,expand=True)\n",
    "df_postings[['Revenue5','new4']]= df_postings['new3'].str.split(' ',n=1,expand=True)\n",
    "\n",
    "\n",
    "#Creating lower bond for Revenue\n",
    "df_postings['Revenue2'] = df_postings['Revenue2'].str.strip('$+')\n",
    "df_postings['Revenue2'] = df_postings['Revenue2'].replace('Unknown', '0')\n",
    "#There is a string that is Less than 1Million so we will make the lower level 0\n",
    "df_postings['Revenue2'] = df_postings['Revenue2'].replace('Less', '0')\n",
    "df_postings['Revenue2'] = df_postings['Revenue2'].astype('int')\n",
    "df_postings.rename(columns={'Revenue2': 'Lower Revenue'}, inplace=True)\n",
    "\n",
    "#There's an instance where the revenue is \" $10+ billion (USD) \" since there is no upper bound we will just set it as 20 billion\n",
    "df_postings.loc[df_postings['Revenue'] == '$10+ billion (USD)', 'Revenue4'] = df_postings.loc[df_postings['Revenue'] == '$10+ billion (USD)', 'Revenue4'].fillna('20')\n",
    "\n",
    "\n",
    "#Creating higher bond for revenue\n",
    "df_postings['Revenue4'] = df_postings['Revenue4'].fillna(0)\n",
    "df_postings['Revenue4'] = df_postings['Revenue4'].astype('int')\n",
    "df_postings.rename(columns={'Revenue4': 'Higher Revenue'}, inplace=True)\n",
    "\n",
    "\n",
    "#Converting values to actual numbers. We have to be careful since the values could be billion or million\n",
    "df_postings.loc[df_postings['Revenue5'] == 'billion', 'Lower Revenue'] *= 1000000000\n",
    "df_postings.loc[df_postings['Revenue5'] == 'billion', 'Higher Revenue'] *= 1000000000\n",
    "df_postings.loc[df_postings['Revenue5'] == 'million', 'Lower Revenue'] *= 1000000\n",
    "df_postings.loc[df_postings['Revenue5'] == 'million', 'Higher Revenue'] *= 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Higher Revenue\n",
       "0              213\n",
       "20              63\n",
       "1000000         14\n",
       "5000000         31\n",
       "10000000        14\n",
       "25000000        41\n",
       "50000000        36\n",
       "100000000       31\n",
       "500000000       94\n",
       "1000000000      19\n",
       "2000000000      36\n",
       "5000000000      45\n",
       "10000000000      8\n",
       "Name: Higher Revenue, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_postings.groupby('Higher Revenue')['Higher Revenue'].count())\n",
    "#Looks like there are still some values that are not being converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Revenue Revenue5  Lower Revenue  Higher Revenue\n",
       "80          $10+ billion (USD)     None             10              20\n",
       "81    $25 to $50 million (USD)  million       25000000        50000000\n",
       "82    $25 to $50 million (USD)  million       25000000        50000000\n",
       "83    Unknown / Non-Applicable     None              0               0\n",
       "84    $25 to $50 million (USD)  million       25000000        50000000\n",
       "85    Unknown / Non-Applicable     None              0               0\n",
       "86    Unknown / Non-Applicable     None              0               0\n",
       "87    $10 to $25 million (USD)  million       10000000        25000000\n",
       "88    Unknown / Non-Applicable     None              0               0\n",
       "89          $10+ billion (USD)     None             10              20\n",
       "90          $10+ billion (USD)     None             10              20\n",
       "91     $5 to $10 million (USD)  million        5000000        10000000\n",
       "92      $1 to $2 billion (USD)  billion     1000000000      2000000000\n",
       "93    Unknown / Non-Applicable     None              0               0\n",
       "94  $100 to $500 million (USD)  million      100000000       500000000\n",
       "95      $2 to $5 billion (USD)  billion     2000000000      5000000000\n",
       "96    $10 to $25 million (USD)  million       10000000        25000000\n",
       "97          $10+ billion (USD)     None             10              20\n",
       "98    $10 to $25 million (USD)  million       10000000        25000000\n",
       "99          $10+ billion (USD)     None             10              20\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_postings[['Revenue','Revenue5','Lower Revenue','Higher Revenue']][80:100])\n",
    "#From this view we see that we have an entry \"$10+ billion (USD)\" where the split did not work properly. So these values are not being converted to billions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              Revenue  Lower Revenue  Higher Revenue  \\\n",
       "12   $500 million to $1 billion (USD)      500000000      1000000000   \n",
       "48           Unknown / Non-Applicable              0               0   \n",
       "177  $500 million to $1 billion (USD)      500000000      1000000000   \n",
       "264  $500 million to $1 billion (USD)      500000000      1000000000   \n",
       "275            $1 to $2 billion (USD)     1000000000      2000000000   \n",
       "300                $10+ billion (USD)    10000000000     20000000000   \n",
       "323          Unknown / Non-Applicable              0               0   \n",
       "515          Unknown / Non-Applicable              0               0   \n",
       "589            $2 to $5 billion (USD)     2000000000      5000000000   \n",
       "595          Unknown / Non-Applicable              0               0   \n",
       "\n",
       "    Currency Multiplier  \n",
       "12              billion  \n",
       "48                 None  \n",
       "177             billion  \n",
       "264             billion  \n",
       "275             billion  \n",
       "300             billion  \n",
       "323                None  \n",
       "515                None  \n",
       "589             billion  \n",
       "595                None  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here we will just lookup where those entries are and multiply its values\n",
    "df_postings.loc[df_postings['Revenue'] == '$10+ billion (USD)', 'Lower Revenue'] *= 1000000000\n",
    "df_postings.loc[df_postings['Revenue'] == '$10+ billion (USD)', 'Higher Revenue'] *= 1000000000\n",
    "\n",
    "#To keep it consistent we will also update the Revenue5 column\n",
    "df_postings.loc[df_postings['Revenue'] == '$10+ billion (USD)', 'Revenue5'] = 'billion'\n",
    "\n",
    "df_postings.rename(columns={'Revenue5': 'Currency Multiplier'}, inplace=True)\n",
    "\n",
    "#print(df_postings[['Revenue','Currency Multiplier','Lower Revenue','Higher Revenue']][80:100])\n",
    "\n",
    "#After further expection, there is a revenue titled \"$500 million to $1 billion (USD)\" which is being labeled as \"billion\". This is true for the high revenue values but not the low ones.\n",
    "#Let's fix this by hard coding the low revenue\n",
    "df_postings.loc[df_postings['Revenue'] == \"$500 million to $1 billion (USD)\", 'Lower Revenue'] = df_postings.loc[df_postings['Revenue'] == \"$500 million to $1 billion (USD)\", 'Lower Revenue'] = int(500000000)\n",
    "\n",
    "#Double checking with an example\n",
    "print(df_postings[df_postings['Type of ownership']==\"Government\"][['Revenue','Lower Revenue','Higher Revenue','Currency Multiplier']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "Index: 645 entries, 0 to 671\n",
       "Data columns (total 25 columns):\n",
       " #   Column                 Non-Null Count  Dtype  \n",
       "---  ------                 --------------  -----  \n",
       " 0   Job Title              645 non-null    object \n",
       " 1   Salary Estimate        645 non-null    object \n",
       " 2   Job Description        645 non-null    object \n",
       " 3   Rating                 645 non-null    float64\n",
       " 4   Location               645 non-null    object \n",
       " 5   Headquarters           645 non-null    object \n",
       " 6   Size                   645 non-null    object \n",
       " 7   Founded                645 non-null    int64  \n",
       " 8   Type of ownership      645 non-null    object \n",
       " 9   Industry               645 non-null    object \n",
       " 10  Sector                 645 non-null    object \n",
       " 11  Revenue                645 non-null    object \n",
       " 12  Lower Salary Estimate  645 non-null    int64  \n",
       " 13  High Salary Estimate   645 non-null    int64  \n",
       " 14  Company Name           645 non-null    object \n",
       " 15  Lower Staff Size       645 non-null    int64  \n",
       " 16  Higher Staff Size      645 non-null    int64  \n",
       " 17  Lower Revenue          645 non-null    int64  \n",
       " 18  new                    645 non-null    object \n",
       " 19  Revenue3               645 non-null    object \n",
       " 20  new2                   369 non-null    object \n",
       " 21  Higher Revenue         645 non-null    int64  \n",
       " 22  new3                   369 non-null    object \n",
       " 23  Currency Multiplier    432 non-null    object \n",
       " 24  new4                   369 non-null    object \n",
       "dtypes: float64(1), int64(7), object(17)\n",
       "memory usage: 131.0+ KB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_postings.info()\n",
    "df_postings.drop(columns=['new','new2','Revenue3','new4','new3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "Index: 645 entries, 0 to 671\n",
       "Data columns (total 20 columns):\n",
       " #   Column                 Non-Null Count  Dtype  \n",
       "---  ------                 --------------  -----  \n",
       " 0   Job Title              645 non-null    object \n",
       " 1   Salary Estimate        645 non-null    object \n",
       " 2   Job Description        645 non-null    object \n",
       " 3   Rating                 645 non-null    float64\n",
       " 4   Location               645 non-null    object \n",
       " 5   Headquarters           645 non-null    object \n",
       " 6   Size                   645 non-null    object \n",
       " 7   Founded                645 non-null    int64  \n",
       " 8   Type of ownership      645 non-null    object \n",
       " 9   Industry               645 non-null    object \n",
       " 10  Sector                 645 non-null    object \n",
       " 11  Revenue                645 non-null    object \n",
       " 12  Lower Salary Estimate  645 non-null    int64  \n",
       " 13  High Salary Estimate   645 non-null    int64  \n",
       " 14  Company Name           645 non-null    object \n",
       " 15  Lower Staff Size       645 non-null    int64  \n",
       " 16  Higher Staff Size      645 non-null    int64  \n",
       " 17  Lower Revenue          645 non-null    int64  \n",
       " 18  Higher Revenue         645 non-null    int64  \n",
       " 19  Currency Multiplier    432 non-null    object \n",
       "dtypes: float64(1), int64(7), object(12)\n",
       "memory usage: 105.8+ KB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_postings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         ownership  count\n",
       "0                Company - Private    397\n",
       "1                 Company - Public    153\n",
       "2           Nonprofit Organization     36\n",
       "3   Subsidiary or Business Segment     28\n",
       "4                       Government     10\n",
       "5               Other Organization      5\n",
       "6          Private Practice / Firm      4\n",
       "7                          Unknown      4\n",
       "8             College / University      3\n",
       "9                    Self-employed      2\n",
       "10                        Contract      2\n",
       "11                        Hospital      1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Analysis 1\n",
    "#To make a sorted hisplot we need to sort the dataframe. For this case we will create a new df to plot ownership counts\n",
    "ownership_counts = df_postings['Type of ownership'].value_counts()\n",
    "ownership_counts_sorted = ownership_counts.sort_values(ascending=False)\n",
    "\n",
    "#The above code gives us a Series. We need a dataframe to make the hisplot work\n",
    "ownership_df = pd.DataFrame({'ownership': ownership_counts_sorted.index, 'count': ownership_counts_sorted.values})\n",
    "\n",
    "ax1 = sns.histplot(\n",
    "    data=ownership_df,\n",
    "    x=\"ownership\",\n",
    "    weights='count',\n",
    "    discrete=True)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "ax1.bar_label(ax1.containers[0],fontsize=7 ) #adding labels to bar chart\n",
    "plt.show()\n",
    "\n",
    "#We could make it simpler by using a barplot instead. This can make a Series, so no need for a df convertion\n",
    "#ax2 = sns.barplot(data=ownership_df,\n",
    "#            x='ownership',\n",
    "#            y='count')\n",
    "#plt.xticks(rotation=45, horizontalalignment='right')\n",
    "#ax2.bar_label(ax2.containers[0],fontsize=7 ) #adding labels to bar chart\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis 1 Summary\n",
    "#Most of the ownerships are of private company. But what does that tell us about revenue and salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Type of ownership      value_type       value\n",
       "0      Nonprofit Organization   Lower Revenue           0\n",
       "1            Company - Public   Lower Revenue  1000000000\n",
       "2     Private Practice / Firm   Lower Revenue   100000000\n",
       "3            Company - Public   Lower Revenue   100000000\n",
       "4           Company - Private   Lower Revenue           0\n",
       "...                       ...             ...         ...\n",
       "1285        Company - Private  Higher Revenue   100000000\n",
       "1286         Company - Public  Higher Revenue   500000000\n",
       "1287        Company - Private  Higher Revenue           0\n",
       "1288        Company - Private  Higher Revenue     5000000\n",
       "1289         Company - Public  Higher Revenue  2000000000\n",
       "\n",
       "[1290 rows x 3 columns]\n",
       "            Type of ownership      value_type      value\n",
       "0      Nonprofit Organization   Lower Revenue          0\n",
       "2     Private Practice / Firm   Lower Revenue  100000000\n",
       "4           Company - Private   Lower Revenue          0\n",
       "5           Company - Private   Lower Revenue          0\n",
       "9           Company - Private   Lower Revenue          0\n",
       "...                       ...             ...        ...\n",
       "1283        Company - Private  Higher Revenue          0\n",
       "1284        Company - Private  Higher Revenue          0\n",
       "1285        Company - Private  Higher Revenue  100000000\n",
       "1287        Company - Private  Higher Revenue          0\n",
       "1288        Company - Private  Higher Revenue    5000000\n",
       "\n",
       "[984 rows x 3 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Analysis 2. Let's see the staff and revenue numbers of each of the ownerships\n",
    "\n",
    "#We have two columns for lower and high salary estimate values. Let's make them into one column, and have a new column to determine the category \"high or low\" estimate\n",
    "#Think of it as Unpivoting from PowerBI. This will allow us to plot everything in one visual\n",
    "df_melted = df_postings.melt(id_vars='Type of ownership', value_vars=['Lower Salary Estimate', 'High Salary Estimate'], var_name='value_type', value_name='value')\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.boxplot(data=df_melted, x='Type of ownership', y='value', hue='value_type', \n",
    "            #Let's not show the outliners so we can see the visual better\n",
    "            showfliers=False)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.title('Salary Estimate by Ownership')\n",
    "plt.show()\n",
    "\n",
    "#Let's do this for Revenue\n",
    "df_melted2 = df_postings.melt(id_vars='Type of ownership', value_vars=['Lower Revenue', 'Higher Revenue'], var_name='value_type', value_name='value')\n",
    "plt.figure(figsize=(9,6))\n",
    "ax3 = sns.boxplot(data=df_melted2, x='Type of ownership', y='value', hue='value_type', \n",
    "            #Let's not show the outliners so we can see the visual better\n",
    "            showfliers=False)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.title('Revenue Estimate by Ownership W/ Company - Public Included')\n",
    "plt.show()\n",
    "\n",
    "#Looks like the revenue for Company - Public is extremely high so it cuts of the other categories. Let's do another visual but this time lets take out Company - Public\n",
    "df_melted3 = df_melted2\n",
    "df_melted3 = df_melted3[df_melted3['Type of ownership'] != 'Company - Public']\n",
    "ax4 = sns.boxplot(data=df_melted3, x='Type of ownership', y='value', hue='value_type', \n",
    "            #Let's not show the outliners so we can see the visual better\n",
    "            showfliers=False)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.title('Revenue Estimate by Ownership W/O Company - Public')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis 2 Summary.\n",
    "#Althought most companies are Private, their low salary estimates are not as competitive as other types (non profits, public, government, other)\n",
    "#Their high salary estimates do a better job competing with other ownership types but still most of the job listings are less competitive than the above types\n",
    "\n",
    "#For Revenue\n",
    "#Private companies rank 7th in their revenue (for both low and high revenue categories) compared to the other ownership types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['San Francisco, CA', 'New York, NY', 'Washington, DC', 'Boston, MA', 'Chicago, IL', 'Herndon, VA', 'Cambridge, MA', 'McLean, VA', 'United States', 'Chantilly, VA', 'Santa Clara, CA', 'Saint Louis, MO', 'Atlanta, GA', 'Gaithersburg, MD', 'San Diego, CA', 'Reston, VA', 'Redwood City, CA', 'Remote', 'Cincinnati, OH']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Analysis 3\n",
    "#Let's graph the number of postings for each location\n",
    "\n",
    "sns.histplot(\n",
    "    data=df_postings,\n",
    "    x=\"Location\"\n",
    ")\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.title('Number of locations')\n",
    "plt.show()\n",
    "\n",
    "#Looks like there is too many locations. Let's just show the top 20\n",
    "df_location = df_postings[\"Location\"].value_counts()\n",
    "df_location = df_location[:20].sort_values(ascending=False)\n",
    "#We could convert the Serie above to a dataframe so seaborn can plot it. But we can also just specifically tell seaborn to plot using index and values\n",
    "#df_location = pd.DataFrame({\"Location\": df_location.index, 'count': df_location.values})\n",
    "\n",
    "#Plotting Series, and not a dataframe\n",
    "ax5 = sns.barplot(\n",
    "    x=df_location.index,\n",
    "    y=df_location.values\n",
    ")\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "ax5.bar_label(ax5.containers[0],fontsize=7 ) #adding labels to bar chart\n",
    "plt.title('Top 20 locations')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Let's investigate the salary estimates for the top 20 locations with job listings\n",
    "df_melted4 = df_postings.melt(id_vars='Location', value_vars=['Lower Salary Estimate', 'High Salary Estimate'], var_name='value_type', value_name='value')\n",
    "#Here we have all of the locations included. Let just include the top 20\n",
    "#First we need the list of the top 20 locations\n",
    "df_location = pd.DataFrame({\"Location\": df_location.index, 'count': df_location.values})\n",
    "df_20 = df_location.iloc[:, 0].tolist()\n",
    "\n",
    "#Now we filter df_melted4 to only include the locations from the df_20 list\n",
    "df_melted5 = df_melted4[df_melted4['Location'].isin(df_20)]\n",
    "\n",
    "\n",
    "\n",
    "ax6 = sns.boxplot(data=df_melted5, \n",
    "                  x='Location', \n",
    "                  y='value', \n",
    "                  hue='value_type', \n",
    "                  order=df_20, #Not necessary but this manually sorts the x axis in the order of the df_20 list \n",
    "            #Let's not show the outliners so we can see the visual better\n",
    "            showfliers=False)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.title('Revenue Estimate by Job Posting Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data Analysis 3 Summary\n",
    "#There are many locations in the job postings, but SF, NY, and Washington DC have the most postings\n",
    "#Although SF has the most posting, they don't have a competitive lower salary estimate compared to the next ~6 locations with the most job postings\n",
    "#This is not entirely true for their high salary estimate, which is competitive to many locations, but falls short to NY, Chicago, MCLean and Reston, VAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis 4 Correlation\n",
    "#Plotting all numeric columns in a correlation matrix\n",
    "correlation_matrix = df_postings.corr(numeric_only=True, method=\"pearson\")\n",
    "plt.figure(figsize=(14,14), dpi = 40)\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "\n",
    "plt.title(\"Correlation Metrix for Numeric Features\")\n",
    "\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets find the correlation again but this time lets include the non number columns\n",
    "df_numerized = df_postings.copy()\n",
    "\n",
    "for col_name in df_numerized.columns:\n",
    "    if(df_numerized[col_name].dtype == \"object\"):\n",
    "        df_numerized[col_name] = df_numerized[col_name].astype(\"category\") \n",
    "        df_numerized[col_name] = df_numerized[col_name].cat.codes\n",
    "\n",
    "correlation_matrix = df_numerized.corr(numeric_only=True, method=\"pearson\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,14), dpi = 40)\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "\n",
    "plt.title(\"Correlation Metrix for All Columns\")\n",
    "\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary Estimate        Location                -0.000602\n",
       "Location               Salary Estimate         -0.000602\n",
       "Lower Staff Size       High Salary Estimate    -0.001235\n",
       "High Salary Estimate   Lower Staff Size        -0.001235\n",
       "Lower Salary Estimate  Higher Staff Size       -0.001313\n",
       "                                                  ...   \n",
       "Salary Estimate        Lower Salary Estimate   -0.394729\n",
       "Higher Staff Size      Size                    -0.395399\n",
       "Size                   Higher Staff Size       -0.395399\n",
       "Revenue                Currency Multiplier     -0.694516\n",
       "Currency Multiplier    Revenue                 -0.694516\n",
       "Length: 208, dtype: float64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Matrix is big. Let's convert into a tableu and show the top correlated pairs\n",
    "correlation_mat = df_numerized.corr(numeric_only=True)\n",
    "corr_pairs = correlation_mat.unstack()\n",
    "sorted_pairs = corr_pairs.sort_values(ascending=False)\n",
    "#print(sorted_pairs[((sorted_pairs) >0.5) & (sorted_pairs<1)])\n",
    "print(sorted_pairs[((sorted_pairs<0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis #4 Summary\n",
    "#There is a strong correlation between low and high revenue\n",
    "#There is a strong correlation between low and high staff size\n",
    "#There is a strong correlation between low and high salary estimate\n",
    "#There is a week correlation between location and salary estimate\n",
    "#There is a week correlation between founded data and salary estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Title\n",
       "Data Scientist                                                      314\n",
       "Data Engineer                                                        26\n",
       "Senior Data Scientist                                                19\n",
       "Machine Learning Engineer                                            15\n",
       "Data Analyst                                                         12\n",
       "                                                                   ... \n",
       "Sr. Research Associate/ Scientist, NGS prep & Molecular Genomics      1\n",
       "Developer III - Data Science                                          1\n",
       "Hydrogen/Tritium Materials Scientist (Experienced)                    1\n",
       "Data Scientist/Data Analytics Practitioner                            1\n",
       "AI/ML - Machine Learning Scientist, Siri Understanding                1\n",
       "Name: count, Length: 170, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Analysis 5\n",
    "#Let's see the median salary for job titles\n",
    "#Checking how many job titles there are.\n",
    "print(df_postings['Job Title'].value_counts())\n",
    "\n",
    "#There are multiple different job titles. Let's create a function where it shortens these job postings\n",
    "def title_short(title):\n",
    "    if \"manager\" in title.lower():\n",
    "        return \"data manager\"\n",
    "    if \"director\" in title.lower() or \"president\" in title.lower():\n",
    "        return \"data director or president\"\n",
    "    if 'scientist' in title.lower():\n",
    "        return \"data scientist\"\n",
    "    if \"analyst\" in title.lower():\n",
    "        return \"data analyst\"\n",
    "    if \"machine learning\" in title.lower():\n",
    "        return \"machine learning\"\n",
    "    if \"science\" in title.lower():\n",
    "        return \"data scientist\"\n",
    "    if \"engineer\" in title.lower():\n",
    "        return \"data engineer\"\n",
    "    if \"architect\" in title.lower() or \"architecture\" in title.lower():\n",
    "        return \"data architect\"\n",
    "    if \"modeler\" in title.lower():\n",
    "        return \"data modeler\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "df_postings[\"Job Title Short\"] = df_postings['Job Title'].apply(title_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n",
       "    return self._engine.get_loc(casted_key)\n",
       "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
       "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
       "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
       "  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
       "  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
       "KeyError: 'Job Title Short'\n",
       "\n",
       "The above exception was the direct cause of the following exception:\n",
       "\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marioreyes\\.vscode\\extensions\\ms-python.python-2025.2.0-win32-x64\\python_files\\python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 2, in <module>\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py\", line 4102, in __getitem__\n",
       "    indexer = self.columns.get_loc(key)\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
       "    raise KeyError(key) from err\n",
       "KeyError: 'Job Title Short'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_postings.info()\n",
    "print(df_postings['Job Title Short'].value_counts())\n",
    "\n",
    "#Creating a groupby statement to find the median lower and high salary for each job title\n",
    "print(df_postings.groupby('Job Title Short')[['Lower Salary Estimate','High Salary Estimate']].median().sort_values(ascending=False, by='Lower Salary Estimate'))\n",
    "\n",
    "#Let's say we want to group both salary estimates into one. Let's create a new column to get the average for each job title\n",
    "\n",
    "df_postings['Average Salary'] = (df_postings['Lower Salary Estimate'] + df_postings['High Salary Estimate'])/2\n",
    "print(df_postings.groupby('Job Title Short')['Average Salary'].median().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     Job Title              Salary Estimate  \\\n",
       "80          Real World Science, Data Scientist  $79K-$131K (Glassdoor est.)   \n",
       "81                              Data Scientist  $79K-$131K (Glassdoor est.)   \n",
       "82                               Data Engineer  $79K-$131K (Glassdoor est.)   \n",
       "83  Data Scientist - Image and Video Analytics  $79K-$131K (Glassdoor est.)   \n",
       "\n",
       "                                      Job Description  Rating  \\\n",
       "80  Title: Real World Science, Data Scientist\\nLoc...     4.0   \n",
       "81  The Senior Data Scientist will build and impro...     3.6   \n",
       "82  Job Description\\n\\nWhy consider OPI, and why d...     4.7   \n",
       "83  Company Industry: Technology\\nOpportunity: The...     4.9   \n",
       "\n",
       "            Location               Headquarters                 Size  Founded  \\\n",
       "80  Gaithersburg, MD  Cambridge, United Kingdom     10000+ employees     1913   \n",
       "81    Washington, DC              Rockville, MD  51 to 200 employees     2001   \n",
       "82   Saint Louis, MO            Minneapolis, MN  51 to 200 employees     1996   \n",
       "83      Longmont, CO                Chicago, IL    1 to 50 employees     2016   \n",
       "\n",
       "    Type of ownership                   Industry                     Sector  \\\n",
       "80   Company - Public  Biotech & Pharmaceuticals  Biotech & Pharmaceuticals   \n",
       "81  Company - Private                IT Services     Information Technology   \n",
       "82  Company - Private                 Consulting          Business Services   \n",
       "83  Company - Private     Staffing & Outsourcing          Business Services   \n",
       "\n",
       "                     Revenue  Lower Salary Estimate  High Salary Estimate  \\\n",
       "80        $10+ billion (USD)                  79000                131000   \n",
       "81  $25 to $50 million (USD)                  79000                131000   \n",
       "82  $25 to $50 million (USD)                  79000                131000   \n",
       "83  Unknown / Non-Applicable                  79000                131000   \n",
       "\n",
       "       Company Name  Lower Staff Size  Higher Staff Size  Lower Revenue  \\\n",
       "80      AstraZeneca             10000              20000    10000000000   \n",
       "81         Powertek                51                200       25000000   \n",
       "82  Object Partners                51                200       25000000   \n",
       "83  The Mom Project                 1                 50              0   \n",
       "\n",
       "    Higher Revenue Currency Multiplier             new            new2  \\\n",
       "80     20000000000             billion  data scientist  data scientist   \n",
       "81        50000000             million  data scientist  data scientist   \n",
       "82        50000000             million            None   data engineer   \n",
       "83               0                None  data scientist  data scientist   \n",
       "\n",
       "   Job Title Short  Average Salary  \n",
       "80  data scientist        105000.0  \n",
       "81  data scientist        105000.0  \n",
       "82   data engineer        105000.0  \n",
       "83  data scientist        105000.0  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Summary 5 Summary\n",
    "#Data architect jobs tend to have the highest pay BUT this assumption is made up from just 1 available job posting\n",
    "#The second highest pay job is data director or president, but its made up of only 4 job listings. Making it also unreliable\n",
    "#Data scientiest roles, which has over 500+ job postings, rank 3rd in salary. Althought they aren't the highest compensated position, this figure does give us a better representation of what someone should expect from this job title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seniority\n",
       "Not Labeled    564\n",
       "Senior          79\n",
       "Entry            2\n",
       "Name: count, dtype: int64\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marioreyes\\.vscode\\extensions\\ms-python.python-2025.2.0-win32-x64\\python_files\\python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 17, in <module>\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py\", line 9183, in groupby\n",
       "    return DataFrameGroupBy(\n",
       "        obj=self,\n",
       "    ...<7 lines>...\n",
       "        dropna=dropna,\n",
       "    )\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 1329, in __init__\n",
       "    grouper, exclusions, obj = get_grouper(\n",
       "                               ~~~~~~~~~~~^\n",
       "        obj,\n",
       "        ^^^^\n",
       "    ...<5 lines>...\n",
       "        dropna=self.dropna,\n",
       "        ^^^^^^^^^^^^^^^^^^^\n",
       "    )\n",
       "    ^\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\groupby\\grouper.py\", line 1043, in get_grouper\n",
       "    raise KeyError(gpr)\n",
       "KeyError: 'Job Title Short'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Analysis 6\n",
    "#We just discovered that some jobs are either entry, junior, or senior positions.\n",
    "#Let's find the median salary for these positions and compare them\n",
    "\n",
    "#Making a function where it will label a job as junior/entry or senior\n",
    "\n",
    "def senority(Job_Title):\n",
    "    if \"junior\" in Job_Title.lower() or \"entry\" in Job_Title.lower() or \"jr\" in Job_Title.lower():\n",
    "        return \"Entry\"\n",
    "    if \"senior\" in Job_Title.lower() or \"sr\" in Job_Title.lower() or \"experienced\" in Job_Title.lower():\n",
    "        return \"Senior\"\n",
    "    else:\n",
    "        return \"Not Labeled\"\n",
    "    \n",
    "df_postings['Seniority'] = df_postings['Job Title'].apply(senority)\n",
    "print(df_postings['Seniority'].value_counts())\n",
    "print(df_postings.groupby(['Job Title Short','Seniority'])['Average Salary'].median())\n",
    "\n",
    "#We could also use a pivot table to show values\n",
    "#pd.pivot_table(df_postings, index=['Job Title Short','Seniority'], values= 'Average Salary', aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marioreyes\\.vscode\\extensions\\ms-python.python-2025.2.0-win32-x64\\python_files\\python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 1, in <module>\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\reshape\\pivot.py\", line 102, in pivot_table\n",
       "    table = __internal_pivot_table(\n",
       "        data,\n",
       "    ...<9 lines>...\n",
       "        sort,\n",
       "    )\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\reshape\\pivot.py\", line 148, in __internal_pivot_table\n",
       "    raise KeyError(i)\n",
       "KeyError: 'Average Salary'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.pivot_table(df_postings, index=['Rating'], values= 'Average Salary', aggfunc='median')\n",
    "#Checking if the rating of the company has any affect to salary\n",
    "#From the correlation earlier, we know that rating and lower/high salary estimates don't have a large correlation\n",
    "#This table is giving us a visual on how the median salary is around 100-120K regardless of rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             OLS Regression Results                             \n",
       "================================================================================\n",
       "Dep. Variable:     High_Salary_Estimate   R-squared:                       0.822\n",
       "Model:                              OLS   Adj. R-squared:                  0.822\n",
       "Method:                   Least Squares   F-statistic:                     2977.\n",
       "Date:                  Fri, 28 Mar 2025   Prob (F-statistic):          1.74e-243\n",
       "Time:                          13:06:24   Log-Likelihood:                -7313.7\n",
       "No. Observations:                   645   AIC:                         1.463e+04\n",
       "Df Residuals:                       643   BIC:                         1.464e+04\n",
       "Df Model:                             1                                         \n",
       "Covariance Type:              nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept              1.787e+04   2515.190      7.106      0.000    1.29e+04    2.28e+04\n",
       "Lower_Salary_Estimate     1.3169      0.024     54.565      0.000       1.269       1.364\n",
       "==============================================================================\n",
       "Omnibus:                       57.528   Durbin-Watson:                   0.089\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.897\n",
       "Skew:                          -0.782   Prob(JB):                     1.09e-15\n",
       "Kurtosis:                       2.660   Cond. No.                     3.27e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.27e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Line of best fit for salary\n",
    "# Create subset of data\n",
    "ols_data = df_postings[[\"High Salary Estimate\",\"Lower Salary Estimate\"]]\n",
    "\n",
    "# Rename columns to remove spaces\n",
    "ols_data.rename(columns={'High Salary Estimate': 'High_Salary_Estimate'}, inplace=True)\n",
    "ols_data.rename(columns={'Lower Salary Estimate': 'Lower_Salary_Estimate'}, inplace=True)\n",
    "\n",
    "#Write formula as text. Dependent variable (y) first, then independent (x)\n",
    "ols_formula = \"High_Salary_Estimate ~ Lower_Salary_Estimate\"\n",
    "\n",
    "#Import libraries\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#build OLS\n",
    "model = ols(formula=ols_formula, data=ols_data).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'Lower_Salary_Estimate', y = \"High_Salary_Estimate\", data = ols_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             OLS Regression Results                             \n",
       "================================================================================\n",
       "Dep. Variable:     High_Salary_Estimate   R-squared:                       0.000\n",
       "Model:                              OLS   Adj. R-squared:                 -0.002\n",
       "Method:                   Least Squares   F-statistic:                   0.01189\n",
       "Date:                  Fri, 28 Mar 2025   Prob (F-statistic):              0.913\n",
       "Time:                          12:59:27   Log-Likelihood:                -6731.5\n",
       "No. Observations:                   554   AIC:                         1.347e+04\n",
       "Df Residuals:                       552   BIC:                         1.348e+04\n",
       "Df Model:                             1                                         \n",
       "Covariance Type:              nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.556e+05   9.52e+04      1.634      0.103   -3.15e+04    3.43e+05\n",
       "Founded       -5.2324     47.981     -0.109      0.913     -99.480      89.015\n",
       "==============================================================================\n",
       "Omnibus:                      209.846   Durbin-Watson:                   0.123\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              853.308\n",
       "Skew:                           1.703   Prob(JB):                    5.09e-186\n",
       "Kurtosis:                       8.036   Cond. No.                     9.70e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.7e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create subset of data\n",
    "#print(df_postings.head(1))\n",
    "ols_data2 = df_postings[[\"High Salary Estimate\",\"Founded\"]]\n",
    "ols_data2 = ols_data2[ols_data2['Founded'] != -1]\n",
    "#print(ols_data2)\n",
    "\n",
    "\n",
    "# Rename columns to remove spaces\n",
    "ols_data2.rename(columns={'High Salary Estimate': 'High_Salary_Estimate'}, inplace=True)\n",
    "\n",
    "#Write formula as text. Dependent variable (y) first, then independent (x)\n",
    "ols_formula = \"High_Salary_Estimate ~ Founded\"\n",
    "\n",
    "#Import libraries\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#build OLS\n",
    "model = ols(formula=ols_formula, data=ols_data2).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n",
       "    return self._engine.get_loc(casted_key)\n",
       "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
       "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
       "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
       "  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
       "  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
       "KeyError: 'Founded'\n",
       "\n",
       "The above exception was the direct cause of the following exception:\n",
       "\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marioreyes\\.vscode\\extensions\\ms-python.python-2025.2.0-win32-x64\\python_files\\python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 1, in <module>\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\seaborn\\regression.py\", line 763, in regplot\n",
       "    plotter = _RegressionPlotter(x, y, data, x_estimator, x_bins, x_ci,\n",
       "                                 scatter, fit_reg, ci, n_boot, units, seed,\n",
       "                                 order, logistic, lowess, robust, logx,\n",
       "                                 x_partial, y_partial, truncate, dropna,\n",
       "                                 x_jitter, y_jitter, color, label)\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\seaborn\\regression.py\", line 107, in __init__\n",
       "    self.establish_variables(data, x=x, y=y, units=units,\n",
       "    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             x_partial=x_partial, y_partial=y_partial)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\seaborn\\regression.py\", line 44, in establish_variables\n",
       "    vector = data[val]\n",
       "             ~~~~^^^^^\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py\", line 4102, in __getitem__\n",
       "    indexer = self.columns.get_loc(key)\n",
       "  File \"C:\\Users\\marioreyes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
       "    raise KeyError(key) from err\n",
       "KeyError: 'Founded'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x = 'Founded', y = \"High_Salary_Estimate\", data = ols_data2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
